{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Cuda available:  True\n",
      "Cuda current device:  0\n",
      "Cuda device s:  <torch.cuda.device object at 0x7fdc2f29db50>\n",
      "Cuda device count:  1\n",
      "Cuda device name:  NVIDIA GeForce RTX 3060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-23 19:56:47.175192: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-23 19:56:47.208103: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-06-23 19:56:47.208119: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Nötige Imports\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, RobertaTokenizer\n",
    "import tensorflow as tf\n",
    "tf.keras.__version__\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import fileinput\n",
    "\n",
    "# GPU benutzen\n",
    "try:\n",
    "    print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Cuda available: \", torch.cuda.is_available())\n",
    "    print(\"Cuda current device: \", torch.cuda.current_device())\n",
    "    print(\"Cuda device s: \", torch.cuda.device(0))\n",
    "    print(\"Cuda device count: \", torch.cuda.device_count())\n",
    "    print(\"Cuda device name: \", torch.cuda.get_device_name(0))\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    memli=4000\n",
    "    if gpus:\n",
    "        try:\n",
    "            tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=memli)])\n",
    "            print(\"Memory limit for gpu is\", memli,\"mb\")\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "except RuntimeError as e:\n",
    "    print(\"no gpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer importieren, Modell erstellen\n",
    "tokenizer2 =  RobertaTokenizer.from_pretrained(\"bhadresh-savani/roberta-base-emotion\", do_lower_case=True)\n",
    "\n",
    "# BERT-Pipeline erstellen\n",
    "classifier = pipeline(\"text-classification\",model='bhadresh-savani/roberta-base-emotion', return_all_scores=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zur Ermittlung des Durchschnitts der Scores\n",
    "def calc_scores (temp_list_pred):\n",
    "    score_sadness = 0\n",
    "    score_joy = 0\n",
    "    score_love = 0\n",
    "    score_anger = 0\n",
    "    score_fear = 0\n",
    "    score_suprise = 0\n",
    "\n",
    "    for x in temp_list_pred:\n",
    "        score_sadness += x[0][0][\"score\"]\n",
    "        score_joy += x[0][1][\"score\"]\n",
    "        score_love += x[0][2][\"score\"]\n",
    "        score_anger += x[0][3][\"score\"]\n",
    "        score_fear += x[0][4][\"score\"]\n",
    "        score_suprise += x[0][5][\"score\"]\n",
    "\n",
    "    score_sadness = score_sadness/le\n",
    "    score_joy = score_joy/le\n",
    "    score_love = score_love/le\n",
    "    score_anger = score_anger/le \n",
    "    score_fear = score_fear/le\n",
    "    score_suprise = score_suprise/le\n",
    "    list_all = [score_sadness,score_joy,score_love,score_anger,score_fear,score_suprise]\n",
    "    \n",
    "    return(list_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modell anwenden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading from: /home/keks/Documents/GitHub/nlp_wapo/data/v6/rdy/16/test/4_rdy.json\n",
      "rdy\n"
     ]
    }
   ],
   "source": [
    "# Variablen erstellen\n",
    "temp_list_pred=[]\n",
    "list_pred = []\n",
    "\n",
    "# Loop durch in Daten-Pipeline erstellte Exports\n",
    "for files in glob.glob(\"/home/keks/Documents/GitHub/nlp_wapo/data/v6/rdy/16/test/*.json\"):\n",
    "    print(\"reading from: \"+ files)\n",
    "    # DF einlesen\n",
    "    df = pd.read_json(files)\n",
    "    \n",
    "    # DF kürzen für Prototyp\n",
    "    df = df[:5]\n",
    "    \n",
    "    # Loop durch DF\n",
    "    for lines in df.content:\n",
    "        \n",
    "        # Wenn über 500 Chars, dann durchreichen in einzelnen Teilen zur Analyse-Pipeline\n",
    "        if len(lines) >= 500:\n",
    "\n",
    "            # Temporäre Variablen\n",
    "            le = int(len(lines)/500)\n",
    "            start = 0\n",
    "            end = 500\n",
    "            i = 1 \n",
    "\n",
    "            while i <= le:\n",
    "                prediction = classifier(lines[start:end],)\n",
    "                temp_list_pred.append(prediction)\n",
    "                start = end\n",
    "                end = end + 500\n",
    "                i+=1\n",
    "\n",
    "            prediction = classifier(lines[start:len(lines)],)\n",
    "            temp_list_pred.append(prediction)\n",
    "\n",
    "        else:\n",
    "            prediction = classifier(lines,)\n",
    "            temp_list_pred.append(prediction)\n",
    "\n",
    "        # Ermittlung der Score Durchschnitte\n",
    "        res = calc_scores(temp_list_pred)\n",
    "        list_pred.append(res)\n",
    "        \n",
    "    # Predictions an DF anhängen\n",
    "    df[\"scores\"] = list_pred\n",
    "    \n",
    "print(\"rdy\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kategorie</th>\n",
       "      <th>Titel</th>\n",
       "      <th>Autor</th>\n",
       "      <th>Datum</th>\n",
       "      <th>content</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43068</th>\n",
       "      <td>Capital Business</td>\n",
       "      <td>Deltek: High-value competitions coming in the ...</td>\n",
       "      <td>Ashley Bergander</td>\n",
       "      <td>2014-09-07T19:33:27Z</td>\n",
       "      <td>Some major federal contracts are up for compet...</td>\n",
       "      <td>[0.030104692559689283, 0.9396944791078568, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43069</th>\n",
       "      <td>Capital Business</td>\n",
       "      <td>District company spins silver into yarn</td>\n",
       "      <td>Abha Bhattarai</td>\n",
       "      <td>2014-09-07T19:38:51Z</td>\n",
       "      <td>Laurie Gonyea has created a 12-step program to...</td>\n",
       "      <td>[0.04154728923458606, 1.2973899831995368, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43070</th>\n",
       "      <td>Capital Business</td>\n",
       "      <td>Washington-area business diary for week of Sep...</td>\n",
       "      <td>Shawn Selby</td>\n",
       "      <td>2014-09-07T19:39:47Z</td>\n",
       "      <td>\"Short takes on the weeks announcements and de...</td>\n",
       "      <td>[0.13987362353752056, 4.427117166419824, 0.082...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43071</th>\n",
       "      <td>Capital Business</td>\n",
       "      <td>Commentary: Our brave new world of communication</td>\n",
       "      <td>Greg Kihlström</td>\n",
       "      <td>2014-09-07T19:42:04Z</td>\n",
       "      <td>More than any other skill in business, none ma...</td>\n",
       "      <td>[0.0644283319124952, 2.7113710632547736, 0.041...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43072</th>\n",
       "      <td>Capital Business</td>\n",
       "      <td>Career Coach: Tips for getting caught up</td>\n",
       "      <td>Joyce E.A. Russell</td>\n",
       "      <td>2014-09-07T19:44:04Z</td>\n",
       "      <td>We just celebrated Labor Day, a tribute to the...</td>\n",
       "      <td>[0.224168244516477, 6.395383497700095, 0.09251...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Kategorie                                              Titel  \\\n",
       "43068  Capital Business  Deltek: High-value competitions coming in the ...   \n",
       "43069  Capital Business            District company spins silver into yarn   \n",
       "43070  Capital Business  Washington-area business diary for week of Sep...   \n",
       "43071  Capital Business   Commentary: Our brave new world of communication   \n",
       "43072  Capital Business           Career Coach: Tips for getting caught up   \n",
       "\n",
       "                    Autor                 Datum  \\\n",
       "43068    Ashley Bergander  2014-09-07T19:33:27Z   \n",
       "43069      Abha Bhattarai  2014-09-07T19:38:51Z   \n",
       "43070         Shawn Selby  2014-09-07T19:39:47Z   \n",
       "43071      Greg Kihlström  2014-09-07T19:42:04Z   \n",
       "43072  Joyce E.A. Russell  2014-09-07T19:44:04Z   \n",
       "\n",
       "                                                 content  \\\n",
       "43068  Some major federal contracts are up for compet...   \n",
       "43069  Laurie Gonyea has created a 12-step program to...   \n",
       "43070  \"Short takes on the weeks announcements and de...   \n",
       "43071  More than any other skill in business, none ma...   \n",
       "43072  We just celebrated Labor Day, a tribute to the...   \n",
       "\n",
       "                                                  scores  \n",
       "43068  [0.030104692559689283, 0.9396944791078568, 0.0...  \n",
       "43069  [0.04154728923458606, 1.2973899831995368, 0.02...  \n",
       "43070  [0.13987362353752056, 4.427117166419824, 0.082...  \n",
       "43071  [0.0644283319124952, 2.7113710632547736, 0.041...  \n",
       "43072  [0.224168244516477, 6.395383497700095, 0.09251...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.030104692559689283,\n",
       " 0.9396944791078568,\n",
       " 0.015655590686947107,\n",
       " 0.1993081532418728,\n",
       " 0.06142737390473485,\n",
       " 0.003809720539720729]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.scores[43068]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0\tsadness <br>\n",
    "1 \tjoy <br>\n",
    "2\tlove <br>\n",
    "3\tanger <br>\n",
    "4\tfear <br>\n",
    "5\tsuprise <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading from: /home/keks/Documents/GitHub/nlp_wapo/data/v6/rdy/16/test/4_rdy.json\n"
     ]
    }
   ],
   "source": [
    "for files in glob.glob(\"/home/keks/Documents/GitHub/nlp_wapo/data/v6/rdy/16/test/*.json\"):\n",
    "    print(\"reading from: \"+ files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "632924e73c662d7eb2092878768cabae4c1618472e5b2e0bb7284b4110ee9d56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
