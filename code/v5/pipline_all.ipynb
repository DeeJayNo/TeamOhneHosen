{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64021e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fileinput\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import pickle\n",
    "\n",
    "from tssplit import tssplit\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66999d4b",
   "metadata": {},
   "source": [
    "!pip3 install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83dc9524",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 12s, sys: 3min 12s, total: 6min 24s\n",
      "Wall time: 6min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = pd.read_json('/home/dave/NLP/WashingtonPost-v4/data/TREC_Washington_Post_collection.v4.jl', lines=True)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ff31eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#im ersten durchlauf gedropped\n",
    "df.drop('article_url', inplace=True, axis=1)\n",
    "df.drop('published_date', inplace=True, axis=1)\n",
    "df.drop('content', inplace=True, axis=1)\n",
    "df.drop('publish_date', inplace=True, axis=1)\n",
    "df.drop('orig-id', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f055849",
   "metadata": {},
   "outputs": [],
   "source": [
    "#im zweiten durchlauf gedropped\n",
    "df.drop('id', inplace=True, axis=1)\n",
    "df.drop('type', inplace=True, axis=1)\n",
    "df.drop('source', inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba906a7a-638c-415c-9030-6aa467b3b8c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b43b4b0-66ac-430e-8c99-c7567c394463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44cd732b-13f5-42f0-a0a6-0ac5089734c6",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d76bfb15-4439-42a8-97a5-a12636cb555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(l):\n",
    "    return list(set(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5df8e3b-2d5e-4046-a907-fa494c68a847",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_auth = \"Â—\\s*\\w*\"\n",
    "drop_list = []\n",
    "index = 0\n",
    "i = 0\n",
    "\n",
    "\n",
    "\n",
    "for auth in df[\"author\"]:\n",
    "  i = 0\n",
    "  at = re.search(pattern_auth, str(auth))\n",
    "  if at or len(str(auth)) <= 4:\n",
    "      drop_list.append(i)\n",
    "  if auth == \"\":\n",
    "    drop_list.append(i)\n",
    "  i+= 1\n",
    "    \n",
    "for tit in df[\"title\"]:\n",
    "  i = 0\n",
    "  if len(str(tit)) <= 4:\n",
    "    drop_list.append(i)\n",
    "  if auth == \"\":\n",
    "    drop_list.append(i)\n",
    "  i+= 1\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2874ff2-b285-4ea2-bbbe-0facd08965ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(remove_duplicates(drop_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5137b002-f3f0-4b25-a1f2-affd9421f57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.sort_index()\n",
    "df = df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5333128c-15a3-44c5-8521-b2ce53a07909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b73ddcc4-079a-4b9f-8726-65c34a985640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 35s, sys: 9.49 s, total: 1min 45s\n",
      "Wall time: 2min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "le = int(len(df)/8)\n",
    "start = 0\n",
    "end = le\n",
    "i = 1 \n",
    "while i < 9:\n",
    "    df[start:end].to_pickle(\"/home/dave/NLP/WashingtonPost-v4/data/\"+str(i)+\".pkl\")\n",
    "    start = end\n",
    "    end = end + le\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c102a1e-6fa1-4334-a494-1c31d754fd53",
   "metadata": {},
   "source": [
    "# Kernel neu starten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c68c7d2f-c61e-4ebe-8cd9-1be71c814d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fileinput\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import pickle\n",
    "\n",
    "from tssplit import tssplit\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbaf9bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### nur beim zweiten durchlauf\n",
    "dfKat_behalten = pd.read_csv(\"P:/uni/nlp/WashingtonPost_v4/Kategorie_behalten.CSV\",header=None)\n",
    "Kat_behalten = list(dfKat_behalten[0])\n",
    "bool_kat = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec8dc149",
   "metadata": {},
   "outputs": [],
   "source": [
    "### nur beim zweiten durchlauf\n",
    "### funktion \n",
    "def ist_in_kat(x):\n",
    "    if x in Kat_behalten:\n",
    "        bool_kat_temp = False\n",
    "    else:\n",
    "        bool_kat_temp = True\n",
    "    return bool_kat_temp\n",
    "\n",
    "\n",
    "for thema in df[\"\"]:\n",
    "  i = 0\n",
    "  bool_kat = ist_in_kat(thema)\n",
    "  if bool_kat:\n",
    "    drop_list.append(i)\n",
    "  i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adf3f64d-93f8-45ec-894d-0bfd7c0ccacb",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/dave/NLP/WashingtonPost-v4/data/1.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:8\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/pickle.py:187\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[39mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[39m4    4    9\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[39m\"\"\"\u001b[39;00m  \u001b[39m# noqa: E501\u001b[39;00m\n\u001b[1;32m    186\u001b[0m excs_to_catch \u001b[39m=\u001b[39m (\u001b[39mAttributeError\u001b[39;00m, \u001b[39mImportError\u001b[39;00m, \u001b[39mModuleNotFoundError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m)\n\u001b[0;32m--> 187\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[1;32m    188\u001b[0m     filepath_or_buffer,\n\u001b[1;32m    189\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    190\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m    191\u001b[0m     is_text\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    192\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    193\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[1;32m    194\u001b[0m \n\u001b[1;32m    195\u001b[0m     \u001b[39m# 1) try standard library Pickle\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[39m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[1;32m    197\u001b[0m     \u001b[39m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m         \u001b[39m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[1;32m    201\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/common.py:798\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    789\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[1;32m    790\u001b[0m             handle,\n\u001b[1;32m    791\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    794\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    795\u001b[0m         )\n\u001b[1;32m    796\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 798\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(handle, ioargs\u001b[39m.\u001b[39;49mmode)\n\u001b[1;32m    799\u001b[0m     handles\u001b[39m.\u001b[39mappend(handle)\n\u001b[1;32m    801\u001b[0m \u001b[39m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/dave/NLP/WashingtonPost-v4/data/1.pkl'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pattern_paragraph = \"\\'subtype\\': \\'paragraph\\'\"\n",
    "pattern_date = \"\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}Z\"\n",
    "\n",
    "\n",
    "\n",
    "for c in range(1,9):\n",
    "    \n",
    "    df = pd.read_pickle(\"/home/dave/NLP/WashingtonPost-v4/data/\"+str(c)+\".pkl\")\n",
    "    \n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    meta_List = []\n",
    "    content_List = []\n",
    "\n",
    "    j= 0\n",
    "\n",
    "    for article in df[\"contents\"]:\n",
    "        temp_List_meta = []\n",
    "        temp_List_content = []\n",
    "        temp_List_content2 = []\n",
    "        temp_List_meta2 = []\n",
    "        temp_List_meta4 = []\n",
    "\n",
    "        for eintrag in article:\n",
    "            x = re.search(pattern_paragraph, str(eintrag))\n",
    "            if x:\n",
    "                temp_List_content = [eintrag]\n",
    "                for t in temp_List_content:\n",
    "                    val = str(t)\n",
    "                    val3 = tssplit(val,quote=\"'\", delimiter=\",\")\n",
    "                    t4 = val3[0][10:]\n",
    "                    temp_List_content2.append(t4)\n",
    "            else:\n",
    "                temp_List_meta = [eintrag]\n",
    "                for t in temp_List_meta:\n",
    "\n",
    "                    val2 = str(t)\n",
    "                    val6 = val2.split(\",\")\n",
    "                    t8 = val6[0][13:]\n",
    "                    temp_List_meta2.append(t8)\n",
    "        \n",
    "        ### hier eine abfrage nach den Kategorien aus der liste machen\n",
    "        \n",
    "            if  bool_kat:\n",
    "                temp_List_meta4.append(temp_List_meta2[0])\n",
    "            #temp_List_meta4.append(temp_List_meta2[1])\n",
    "            else:\n",
    "                print()\n",
    "        \n",
    "        \n",
    "        \n",
    "        temp_List_meta4.append(df[\"title\"][j])   #neu muss noch getetstet werden\n",
    "        temp_List_meta4.append(df[\"author\"][j])\n",
    "\n",
    "        for m in temp_List_meta2:                \n",
    "            d = re.search(pattern_date, str(m))          \n",
    "            if d:\n",
    "                temp_List_meta4.append(m)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        if len(temp_List_meta4) >= 3 and len(temp_List_meta4) <= 4 and len(temp_List_content2) > 3:\n",
    "            #if temp_List_meta4[0]\n",
    "            meta_List.append(temp_List_meta4)    \n",
    "            content_List.append(\"\".join(temp_List_content2))\n",
    "\n",
    "        j+=1        \n",
    "\n",
    "    dfMeta = pd.DataFrame(meta_List)\n",
    "    dfContent = pd.DataFrame(content_List)\n",
    "\n",
    "    dfContent = dfContent.set_axis([\"content\"], axis=1, inplace = False)\n",
    "\n",
    "    dfMeta = dfMeta.set_axis([\"Kategorie\",\"Titel\",\"Autor\",\"Datum\"], axis=1, inplace = False)\n",
    "\n",
    "    dfContent[\"id\"] = dfContent.index\n",
    "    dfMeta[\"id1\"] = dfMeta.index\n",
    "\n",
    "    df = pd.merge(dfMeta,dfContent, left_on=\"id1\", right_on=\"id\", how=\"left\").drop(\"id1\",axis=1)\n",
    "    \n",
    "    df.to_pickle(\"/home/dave/NLP/WashingtonPost-v4/data/\"+str(c)+\"_raw.pkl\")\n",
    "\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b3e514-297c-49e1-9ed2-3bb445c5db61",
   "metadata": {},
   "source": [
    "# Kernel neu starten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ee4c0e-eb93-443c-93b8-a750aaa8fef1",
   "metadata": {},
   "source": [
    "## 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e24dba47-62b4-4d39-a947-53a5a64c4f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "tqdm.pandas()\n",
    "import fileinput\n",
    "import pickle\n",
    "import re\n",
    "import spacy\n",
    "from pandarallel import pandarallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207f0fa3-288a-404c-9bf2-350f28a2d9f9",
   "metadata": {},
   "source": [
    "!python -m spacy download en_core_web_md <br>\n",
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bd0dadb-361f-4f43-abf0-bd9e4ff00940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.8 s, sys: 8.24 s, total: 46 s\n",
      "Wall time: 55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for c in range(1,9):\n",
    "    \n",
    "    df = pd.read_pickle(\"/home/dave/NLP/WashingtonPost-v4/data/\"+str(c)+\"_raw.pkl\")\n",
    "    \n",
    "    df = df.set_index('id')\n",
    "    \n",
    "    df.Kategorie = df.Kategorie.replace(\"\\\"$|\\'$\", \"\",regex=True)\n",
    "    df.Titel = df.Titel.replace(\"\\\"$|\\'$\", \"\",regex=True)\n",
    "    df.Datum = df.Datum.replace(\"\\\"$|\\'$\", \"\",regex=True) \n",
    "\n",
    "    df.content = df.content.replace(\"\\<.*?\\>\",\"\",regex=True)\n",
    "    \n",
    "    df.to_pickle(\"data/\"+str(c)+\"_clean.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b3e514-297c-49e1-9ed2-3bb445c5db61",
   "metadata": {},
   "source": [
    "# Kernel neu starten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bd506c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "tqdm.pandas()\n",
    "import fileinput\n",
    "import pickle\n",
    "import re\n",
    "import spacy\n",
    "from pandarallel import pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52504d27-3c29-433b-99a3-92fb6fd66bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 22 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "909d1b9f-db7d-4d94-8500-52ca9386568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stopwords = nlp.Defaults.stop_words\n",
    "def remove_stopwords_from_list(list_in):\n",
    "    return [a for a in list_in if a not in all_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f06be8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_pickle(\"P:/uni/nlp/WashingtonPost_v4/data/v5/5_clean.pkl\")\n",
    "#df3 = pd.read_pickle(\"/home/dave/NLP/WashingtonPost-v4/data/3_clean.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73be9578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dcb1c07a9ae485bb09f51f7d2565b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=3761), Label(value='0 / 3761'))), â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2[\"tokens\"] = df2.parallel_apply(lambda row: [a.text for a in list(nlp(str(row[\"content\"])))], axis=1)\n",
    "df2[\"no_stop\"] = df2.parallel_apply(lambda row: remove_stopwords_from_list(row[\"tokens\"]), axis=1)\n",
    "df2[\"lemma\"] = df2.parallel_apply(lambda row: [t.lemma_ for t in nlp(row[\"content\"])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cca5927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ef66a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "074a8ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "tqdm.pandas()\n",
    "import fileinput\n",
    "import pickle\n",
    "import re\n",
    "import spacy\n",
    "from pandarallel import pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5345d5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "kategorie_all = []\n",
    "kategorie = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d95ca17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kategorie = []\n",
    "\n",
    "for c in range(1,9):\n",
    "    \n",
    "    df2 = pd.read_pickle(\"P:/uni/nlp/WashingtonPost_v4/data/v5/\"+str(c)+\"_clean.pkl\")\n",
    "    \n",
    "    for each in df2.Kategorie:\n",
    "        kategorie.append(each)\n",
    "\n",
    "    kategorie_all.append(list(kategorie))\n",
    "    kategorie = []  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bef08fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "endlist = []\n",
    "for each in kategorie_all:\n",
    "    for each2 in each:\n",
    "        endlist.append(each2)\n",
    "        \n",
    "endlist = list(set(endlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e8815ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfKat = pd.DataFrame(endlist)\n",
    "#dfKat\n",
    "dfKat = dfKat.sort_values(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a04df191",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfKat.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1f32971",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfkat_behalten = pd.read_csv(\"P:/uni/nlp/WashingtonPost_v4/Kategorie_behalten.CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36ffe188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All Opinions Are Local</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>America Answers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Americas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Answer Sheet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ask The Post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>By The Way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>The Washington Post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>The Washington Post Magazine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>The Watch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Think Tanked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Today's WorldView</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          All Opinions Are Local\n",
       "0                America Answers\n",
       "1                       Americas\n",
       "2                   Answer Sheet\n",
       "3                   Ask The Post\n",
       "4                     By The Way\n",
       "..                           ...\n",
       "61           The Washington Post\n",
       "62  The Washington Post Magazine\n",
       "63                     The Watch\n",
       "64                  Think Tanked\n",
       "65             Today's WorldView\n",
       "\n",
       "[66 rows x 1 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfkat_behalten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b940c59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "96ea463da8b265c951058de84b9645eca36b660a1a779c7b0eff4941594f7f98"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
